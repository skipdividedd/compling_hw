{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-12T21:40:00.674421Z",
     "iopub.status.busy": "2023-04-12T21:40:00.674124Z",
     "iopub.status.idle": "2023-04-12T21:40:02.025202Z",
     "shell.execute_reply": "2023-04-12T21:40:02.024187Z",
     "shell.execute_reply.started": "2023-04-12T21:40:00.674389Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:40:02.027098Z",
     "iopub.status.busy": "2023-04-12T21:40:02.026437Z",
     "iopub.status.idle": "2023-04-12T21:40:02.174380Z",
     "shell.execute_reply": "2023-04-12T21:40:02.173354Z",
     "shell.execute_reply.started": "2023-04-12T21:40:02.027056Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('en_data.json') as f:\n",
    "    en_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Состав датасета:\n",
    "\n",
    "1. Переведенные данные alpaca (в размере 6639 предложений)\n",
    "2. Данные https://huggingface.co/datasets/Den4ikAI/russian_instructions_2 (30000 предложений)\n",
    "\n",
    "Всего -- 36639 предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:40:02.177679Z",
     "iopub.status.busy": "2023-04-12T21:40:02.177268Z",
     "iopub.status.idle": "2023-04-12T21:40:24.917878Z",
     "shell.execute_reply": "2023-04-12T21:40:24.916829Z",
     "shell.execute_reply.started": "2023-04-12T21:40:02.177641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'инструкция'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-ru\")\n",
    "translator(\"instruction\")[0]['translation_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример, как переводим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:40:24.921150Z",
     "iopub.status.busy": "2023-04-12T21:40:24.920378Z",
     "iopub.status.idle": "2023-04-12T21:40:43.203814Z",
     "shell.execute_reply": "2023-04-12T21:40:43.202750Z",
     "shell.execute_reply.started": "2023-04-12T21:40:24.921101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Назовите пять средиземноморских стран.',\n",
       "  'input': '',\n",
       "  'output': 'Греция, Испания, Италия, Турция, Франция'},\n",
       " {'instruction': 'Нажмите на правильный параметр.',\n",
       "  'input': 'Какой из следующих продуктов питания содержит больше всего сахара? A. Apple B. Orange C. Шоколад',\n",
       "  'output': 'С. Шоколад'},\n",
       " {'instruction': 'Определить количество недель в году.',\n",
       "  'input': '',\n",
       "  'output': 'Количество недель в году составляет 52 недели.'},\n",
       " {'instruction': 'Разработка перечня из пяти шагов для обеспечения успеха проекта.',\n",
       "  'input': '',\n",
       "  'output': '2. Разработка подробного плана и графика; 3. создание группы специально подготовленных специалистов; 4. выявление рисков и разработка стратегий их смягчения; 5. контроль за прогрессом и своевременное внесение коррективов в учебные курсы.'},\n",
       " {'instruction': 'Напиши несколько предложений о важности воды.',\n",
       "  'input': '',\n",
       "  'output': 'Вода является одним из важнейших веществ на Земле, поскольку она необходима всем живым организмам, без воды невозможно жить на Земле.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_data_example = []\n",
    "for i in range(5):\n",
    "    temp = {}\n",
    "    for k, v in en_data[i].items():\n",
    "        if v != \"\":\n",
    "            v = translator(v)[0]['translation_text']\n",
    "        temp[k] = v    \n",
    "    ru_data_example.append(temp)\n",
    "ru_data_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Столько примеров всего:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:40:43.207321Z",
     "iopub.status.busy": "2023-04-12T21:40:43.205222Z",
     "iopub.status.idle": "2023-04-12T21:40:43.340877Z",
     "shell.execute_reply": "2023-04-12T21:40:43.339869Z",
     "shell.execute_reply.started": "2023-04-12T21:40:43.207290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36639"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('ru_data3.json') as f:\n",
    "    ru_data = json.load(f)\n",
    "len(ru_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как выглядят данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:40:43.342732Z",
     "iopub.status.busy": "2023-04-12T21:40:43.342255Z",
     "iopub.status.idle": "2023-04-12T21:40:43.349487Z",
     "shell.execute_reply": "2023-04-12T21:40:43.348299Z",
     "shell.execute_reply.started": "2023-04-12T21:40:43.342688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpaca\n",
      "{'instruction': 'Объясните, почему следующая доля эквивалентна 1/4', 'input': '4/16', 'output': 'Доля 4/16 эквивалентна 1/4, поскольку как числители, так и знаменатели делятся на 4.'}\n",
      "{'instruction': 'Как умер Юлий Цезарь?', 'input': '', 'output': 'Юлий Цезарь был убит группой в составе до 60 заговорщиков, возглавляемой Гаюсом Кассиусом Лонгинусом и Марком Джуниусом Брутусом, в Сенате на Иде (15 марта) 44 года до н. э.'}\n",
      "\n",
      "HuggingFace Dataset\n",
      "{'instruction': ' Я слышал, что иглоукалывание может облегчить боль. Это правда?', 'input': '', 'output': ' Да, иглоукалывание доказало свою эффективность в лечении многих видов боли. Он работает, стимулируя естественную систему обезболивания организма и уменьшая воспаление. Исследования показали, что иглоукалывание может помочь уменьшить такие симптомы, как головная боль, боль в пояснице, боль при артрите и даже боль при фибромиалгии.'}\n"
     ]
    }
   ],
   "source": [
    "print('Alpaca')\n",
    "print(ru_data[6])\n",
    "print(ru_data[10])\n",
    "print()\n",
    "print('HuggingFace Dataset')\n",
    "print(ru_data[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:40:43.351843Z",
     "iopub.status.busy": "2023-04-12T21:40:43.351175Z",
     "iopub.status.idle": "2023-04-12T21:40:43.732939Z",
     "shell.execute_reply": "2023-04-12T21:40:43.731944Z",
     "shell.execute_reply.started": "2023-04-12T21:40:43.351788Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Dict, Sequence\n",
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import Trainer\n",
    "\n",
    "# import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:40:43.735456Z",
     "iopub.status.busy": "2023-04-12T21:40:43.734265Z",
     "iopub.status.idle": "2023-04-12T21:40:43.743678Z",
     "shell.execute_reply": "2023-04-12T21:40:43.740870Z",
     "shell.execute_reply.started": "2023-04-12T21:40:43.735415Z"
    }
   },
   "outputs": [],
   "source": [
    "IGNORE_INDEX = -100\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"</s>\"\n",
    "DEFAULT_UNK_TOKEN = \"</s>\"\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Ниже приведена инструкция, которая описывает задачу в сочетании с вводными данными, предоставляющими дополнительный контекст. \"\n",
    "        \"Напишите ответ, который соответствующим образом завершает запрос.\\n\\n\"\n",
    "        \"### Инструкция:\\n{instruction}\\n\\n### Вводные данные:\\n{input}\\n\\n### Ответ:\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Ниже приведена инструкция, описывающая задачу.\"\n",
    "        \"Напишите ответ, который соответствующим образом завершает запрос.\\n\\n\"\n",
    "        \"### Инструкция:\\n{instruction}\\n\\n### Ответ:\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:40:43.748543Z",
     "iopub.status.busy": "2023-04-12T21:40:43.748275Z",
     "iopub.status.idle": "2023-04-12T21:40:43.756206Z",
     "shell.execute_reply": "2023-04-12T21:40:43.755093Z",
     "shell.execute_reply.started": "2023-04-12T21:40:43.748513Z"
    }
   },
   "outputs": [],
   "source": [
    "def _tokenize_fn(strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "    \"\"\"Tokenize a list of strings.\"\"\"\n",
    "    tokenized_list = [\n",
    "        tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            #padding=\"longest\",\n",
    "            max_length=tokenizer.model_max_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "        for text in strings\n",
    "    ]\n",
    "    input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "    input_ids_lens = labels_lens = [\n",
    "        tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "    ]\n",
    "    return dict(\n",
    "        input_ids=input_ids,\n",
    "        labels=labels,\n",
    "        input_ids_lens=input_ids_lens,\n",
    "        labels_lens=labels_lens,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:40:43.758152Z",
     "iopub.status.busy": "2023-04-12T21:40:43.757733Z",
     "iopub.status.idle": "2023-04-12T21:40:43.771575Z",
     "shell.execute_reply": "2023-04-12T21:40:43.770616Z",
     "shell.execute_reply.started": "2023-04-12T21:40:43.758104Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(\n",
    "    sources: Sequence[str],\n",
    "    targets: Sequence[str],\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    ") -> Dict:\n",
    "    \"\"\"Preprocess the data by tokenizing.\"\"\"\n",
    "    examples = [s + t for s, t in zip(sources, targets)]\n",
    "    examples_tokenized, sources_tokenized = [_tokenize_fn(strings, tokenizer) for strings in (examples, sources)]\n",
    "    input_ids = examples_tokenized[\"input_ids\"]\n",
    "    labels = copy.deepcopy(input_ids)\n",
    "    for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "        label[:source_len] = IGNORE_INDEX\n",
    "    return dict(input_ids=input_ids, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:40:43.773430Z",
     "iopub.status.busy": "2023-04-12T21:40:43.773049Z",
     "iopub.status.idle": "2023-04-12T21:40:43.787282Z",
     "shell.execute_reply": "2023-04-12T21:40:43.786189Z",
     "shell.execute_reply.started": "2023-04-12T21:40:43.773393Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupervisedDataset(Dataset):\n",
    "    \"\"\"Dataset for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str, tokenizer: transformers.PreTrainedTokenizer):\n",
    "        super(SupervisedDataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "        list_data_dict = json.load(open(data_path))\n",
    "\n",
    "        logging.warning(\"Formatting inputs...\")\n",
    "        prompt_input, prompt_no_input = PROMPT_DICT[\"prompt_input\"], PROMPT_DICT[\"prompt_no_input\"]\n",
    "        sources = [\n",
    "            prompt_input.format_map(example) if example.get(\"input\", \"\") != \"\" else prompt_no_input.format_map(example)\n",
    "            for example in list_data_dict\n",
    "        ]\n",
    "        targets = [f\"{example['output']}{tokenizer.eos_token}\" for example in list_data_dict]\n",
    "\n",
    "        logging.warning(\"Tokenizing inputs... This may take some time...\")\n",
    "        data_dict = preprocess(sources, targets, tokenizer)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object):\n",
    "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:40:43.789114Z",
     "iopub.status.busy": "2023-04-12T21:40:43.788754Z",
     "iopub.status.idle": "2023-04-12T21:41:00.337457Z",
     "shell.execute_reply": "2023-04-12T21:41:00.336365Z",
     "shell.execute_reply.started": "2023-04-12T21:40:43.789079Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"facebook/opt-350m\"\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        max_length=512,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:41:00.339633Z",
     "iopub.status.busy": "2023-04-12T21:41:00.339269Z",
     "iopub.status.idle": "2023-04-12T21:41:01.430526Z",
     "shell.execute_reply": "2023-04-12T21:41:01.429493Z",
     "shell.execute_reply.started": "2023-04-12T21:41:00.339594Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    'facebook/opt-350m',\n",
    "    model_max_length=500,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:41:01.432373Z",
     "iopub.status.busy": "2023-04-12T21:41:01.431912Z",
     "iopub.status.idle": "2023-04-12T21:41:44.832520Z",
     "shell.execute_reply": "2023-04-12T21:41:44.831463Z",
     "shell.execute_reply.started": "2023-04-12T21:41:01.432333Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Formatting inputs...\n",
      "WARNING:root:Tokenizing inputs... This may take some time...\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SupervisedDataset(tokenizer=tokenizer, data_path=\"ru_data3.json\")\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -i https://test.pypi.org/simple/ bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:41:44.834782Z",
     "iopub.status.busy": "2023-04-12T21:41:44.834403Z",
     "iopub.status.idle": "2023-04-12T21:41:44.924567Z",
     "shell.execute_reply": "2023-04-12T21:41:44.923620Z",
     "shell.execute_reply.started": "2023-04-12T21:41:44.834743Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = transformers.TrainingArguments(learning_rate=1e-5, \n",
    "                 num_train_epochs=8,\n",
    "                 per_device_train_batch_size=16,\n",
    "                 evaluation_strategy='no',\n",
    "                 weight_decay=0.,\n",
    "                 warmup_ratio=0.03,\n",
    "                 lr_scheduler_type=\"cosine\",\n",
    "                 save_strategy='steps',\n",
    "                 save_steps = 6000,\n",
    "                 logging_steps=1000,\n",
    "                 fp16=True,\n",
    "                 output_dir=\"instruct_ft\",\n",
    "                 dataloader_num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "from torch import nn\n",
    "from transformers.trainer_pt_utils import get_parameter_names\n",
    "\n",
    "\n",
    "decay_parameters = get_parameter_names(model, [nn.LayerNorm])\n",
    "decay_parameters = [name for name in decay_parameters if \"bias\" not in name]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if n in decay_parameters],\n",
    "        \"weight_decay\": training_args.weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if n not in decay_parameters],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    \"betas\": (training_args.adam_beta1, training_args.adam_beta2),\n",
    "    \"eps\": training_args.adam_epsilon,\n",
    "}\n",
    "optimizer_kwargs[\"lr\"] = training_args.learning_rate\n",
    "adam_bnb_optim = bnb.optim.Adam8bit(\n",
    "    optimizer_grouped_parameters,\n",
    "    betas=(training_args.adam_beta1, training_args.adam_beta2),\n",
    "    eps=training_args.adam_epsilon,\n",
    "    lr=training_args.learning_rate,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:41:44.926352Z",
     "iopub.status.busy": "2023-04-12T21:41:44.925968Z",
     "iopub.status.idle": "2023-04-12T21:41:49.418446Z",
     "shell.execute_reply": "2023-04-12T21:41:49.417148Z",
     "shell.execute_reply.started": "2023-04-12T21:41:44.926311Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.imgenv-train-ru-bert-0/lib/python3.7/site-packages/torch/utils/tensorboard/__init__.py:5: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  tensorboard.__version__\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model, \n",
    "                 tokenizer=tokenizer, \n",
    "                 args=training_args,\n",
    "                 train_dataset=train_dataset, \n",
    "                 eval_dataset=None, \n",
    "                 data_collator=data_collator, \n",
    "                 optimizers=(adam_bnb_optim, None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T21:41:49.421333Z",
     "iopub.status.busy": "2023-04-12T21:41:49.420970Z",
     "iopub.status.idle": "2023-04-12T22:55:53.270152Z",
     "shell.execute_reply": "2023-04-12T22:55:53.269161Z",
     "shell.execute_reply.started": "2023-04-12T21:41:49.421299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18320' max='18320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18320/18320 2:55:00, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.175400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.079700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.968700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.917000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.861800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.811500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.779100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.701800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.643000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.619800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.567600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.535900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.507300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.460400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.416300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.414200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18320, training_loss=0.6966662261163303, metrics={'train_runtime': 10504.603, 'train_samples_per_second': 27.903, 'train_steps_per_second': 1.744, 'total_flos': 2.66753568079872e+17, 'train_loss': 0.6966662261163303, 'epoch': 8.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T22:55:53.274775Z",
     "iopub.status.busy": "2023-04-12T22:55:53.271483Z",
     "iopub.status.idle": "2023-04-12T22:55:54.336950Z",
     "shell.execute_reply": "2023-04-12T22:55:54.335239Z",
     "shell.execute_reply.started": "2023-04-12T22:55:53.274730Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model('ft_02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T23:03:38.103931Z",
     "iopub.status.busy": "2023-04-12T23:03:38.103535Z",
     "iopub.status.idle": "2023-04-12T23:03:38.112474Z",
     "shell.execute_reply": "2023-04-12T23:03:38.110881Z",
     "shell.execute_reply.started": "2023-04-12T23:03:38.103897Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T23:03:42.739537Z",
     "iopub.status.busy": "2023-04-12T23:03:42.739147Z",
     "iopub.status.idle": "2023-04-12T23:03:42.746221Z",
     "shell.execute_reply": "2023-04-12T23:03:42.744877Z",
     "shell.execute_reply.started": "2023-04-12T23:03:42.739504Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ft_02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T23:03:46.071485Z",
     "iopub.status.busy": "2023-04-12T23:03:46.071112Z",
     "iopub.status.idle": "2023-04-12T23:03:48.283901Z",
     "shell.execute_reply": "2023-04-12T23:03:48.279765Z",
     "shell.execute_reply.started": "2023-04-12T23:03:46.071454Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, model_max_length=500)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_instruction(instruction, model):\n",
    "    #text = text.replace('\\n', ' ')\n",
    "    prompt = (\"Ниже приведена инструкция, описывающая задачу.\"\n",
    "              \"Напишите ответ, который соответствующим образом завершает запрос.\\n\\n\"\n",
    "               f\"### Инструкция:\\n{instruction}\\n\\n### Ответ:\")\n",
    "\n",
    "    inputs = tokenizer([prompt], \n",
    "                        return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    output_sequences = model.generate(\n",
    "        max_new_tokens=200,\n",
    "        top_k=10, \n",
    "        top_p=0.85, \n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        do_sample=False,  # disable sampling to test if batching affects output\n",
    "    )\n",
    "    summaries = tokenizer.batch_decode(output_sequences[:,len(inputs[0]):], skip_special_tokens=True)\n",
    "    return summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Самый популярный язык — культурный язык.'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Назови самый популярный язык.\"\n",
    "predict_for_instruction(instruction, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T23:11:29.440567Z",
     "iopub.status.busy": "2023-04-12T23:11:29.440187Z",
     "iopub.status.idle": "2023-04-12T23:11:29.449007Z",
     "shell.execute_reply": "2023-04-12T23:11:29.446666Z",
     "shell.execute_reply.started": "2023-04-12T23:11:29.440534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Столица США - Сан-Франциско.'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Назови столицу США.\"\n",
    "predict_for_instruction(instruction, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Врет :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_instruction(instruction, model):\n",
    "    prompt = (\"Ниже приведена инструкция, описывающая задачу.\"\n",
    "              \"Напишите ответ, который соответствующим образом завершает запрос.\\n\\n\"\n",
    "               f\"### Инструкция:\\n{instruction}\\n\\n### Ответ:\")\n",
    "\n",
    "    inputs = tokenizer([prompt], \n",
    "                        return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    output_sequences = model.generate(\n",
    "        max_new_tokens=200,\n",
    "        num_beams=5,\n",
    "        temperature=0.4,\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        do_sample=False,  # disable sampling to test if batching affects output\n",
    "    )\n",
    "    summaries = tokenizer.batch_decode(output_sequences[:,len(inputs[0]):], skip_special_tokens=True)\n",
    "    return summaries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### С такими параметрами отвечает относительно нормально"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Уменьшение загрязнения воздуха является возобновляемым источником энергии, таким, как солнечная энергия, энергия ветра и гидроэлектроэнергия.'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Как можно уменьшить загрязнение воздуха?\"\n",
    "predict_for_instruction(instruction, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Начните с изучения типов вакансий, доступных в интересующей вас области, а затем создайте список потенциальных работодателей, которые могут быть доступны. Вы также можете связатьс'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Как найти работу?\"\n",
    "predict_for_instruction(instruction, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Лучший способ найти жену — это попросить друзей и родственников порекомендовать их.'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Как найти жену?\"\n",
    "predict_for_instruction(instruction, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Бег также лучше, чем плавание.'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Что лучше: бег или плавание?\"\n",
    "predict_for_instruction(instruction, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Регулярно практикуйтесь и сосредоточьтесь на своем дыхании. 2. Избегайте кофеина в конце дня. 3. Регулярно делайте физические упражнения, так как физическая активность может помо�'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Дай совет, как улучшить память.\"\n",
    "predict_for_instruction(instruction, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Одним из оставшихся здоровых привычек является сбалансированное питание, включающее большое количество фруктов и овощей, цельнозерновые продукты, нежирные белки и полезные жиры.'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Как оставаться здоровым?\"\n",
    "predict_for_instruction(instruction, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Лучший способ бросить курить - это сосредоточиться на своем дыхании и убедиться, что у вас есть все необходимые меры предосторожности, такие, как упражнения на глубокое дыхание, прогресс'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Как бросить курить?\"\n",
    "predict_for_instruction(instruction, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Обычно считается безопасным употребление сырых яиц для большинства людей.'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Безопасно ли есть сырые яйца?\"\n",
    "predict_for_instruction(instruction, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Равно 2+2.'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Чему равно 2+2?\"\n",
    "predict_for_instruction(instruction, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логично."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_instruction(instruction, model):\n",
    "    prompt = (\"Ниже приведена инструкция, описывающая задачу.\"\n",
    "              \"Напишите ответ, который соответствующим образом завершает запрос.\\n\\n\"\n",
    "               f\"### Инструкция:\\n{instruction}\\n\\n### Ответ:\")\n",
    "\n",
    "    inputs = tokenizer([prompt], \n",
    "                        return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    output_sequences = model.generate(\n",
    "        max_new_tokens=200,\n",
    "        no_repeat_ngram_size=5, \n",
    "        top_k=0, \n",
    "        top_p=0.92, \n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        do_sample=False,  # disable sampling to test if batching affects output\n",
    "    )\n",
    "    summaries = tokenizer.batch_decode(output_sequences[:,len(inputs[0]):], skip_special_tokens=True)\n",
    "    return summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Чтобы улулуцировать ваши выновленные стандарты, начните с предварительного пространства для выполнения занятий, концентрации и программы. Убедитесь, что вы пребываете под наградой или прод'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Как улучшить выносливость?\"\n",
    "predict_for_instruction(instruction, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод: модель что-то отвечает, но не очень хорошо"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
