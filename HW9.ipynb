{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ ‚Ññ 10. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞","metadata":{"id":"1dba7c0d"}},{"cell_type":"markdown","source":"### –ó–∞–¥–∞–Ω–∏–µ 1 (8 –±–∞–ª–ª–æ–≤).\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥–æ–æ–±—É—á–∞—Ç—å GPT –Ω–∞ –∫–∞–∫–æ–º-—Ç–æ –¥—Ä—É–≥–æ–º —Ç–µ–∫—Å—Ç–µ (–º–æ–∂–µ—Ç–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ª—é–±—ã–µ —Å—Ç–∏—Ö–∏ –∏–ª–∏ –∫–∞–∫–∏–µ-—Ç–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –≤–µ—â–∏ –≤—Ä–æ–¥–µ –∞–Ω–µ–∫–¥–æ—Ç–æ–≤, —Ç–µ–æ—Ä–∏–π –∑–∞–≥–æ–≤–æ—Ä–æ–≤, –ø–æ—Å—Ç–æ–≤ –≤ –ø–æ–º–æ–µ—á–Ω—ã—Ö —Ç–µ–ª–µ–≥—Ä–∞–º –∫–∞–Ω–∞–ª–∞—Ö, —Ç–µ–∫—Å—Ç–æ–≤ –∂—É—Ä–Ω–∞–ª–∏—Å—Ç–æ–≤ –∏ –°–ú–ò —Å –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω—ã–º —Å—Ç–∏–ª–µ–º). \n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (beam search, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, top_k –∏ —Ç–ø). –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –≤ —Ç–µ—Ç—Ä–∞–¥–∫–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–∏—Ö —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤\n","metadata":{"id":"76f21d5e"}},{"cell_type":"code","source":"#!pip install transformers","metadata":{"id":"2444e3fe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a0f2c7f1-7087-48a0-a110-a1c9a75e0592","execution":{"iopub.status.busy":"2023-03-19T18:52:28.267061Z","iopub.execute_input":"2023-03-19T18:52:28.267862Z","iopub.status.idle":"2023-03-19T18:52:28.334303Z","shell.execute_reply.started":"2023-03-19T18:52:28.267829Z","shell.execute_reply":"2023-03-19T18:52:28.333402Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport torch\nDEVICE = torch.device(\"cuda:0\")\n\n# –≤–æ–∑—å–º–µ–º –º–æ–¥–µ–ª—å –ø–æ–º–µ–Ω—å—à–µ, —Ç–∞–∫ –∫–∞–∫ –¥–æ–æ–±—É—á–µ–Ω–∏–µ —ç—Ç–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤\nmodel_name_or_path = \"sberbank-ai/rugpt3small_based_on_gpt2\"\ntokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\nmodel = GPT2LMHeadModel.from_pretrained(model_name_or_path, use_cache=False).to(DEVICE)","metadata":{"id":"f07bd89b","execution":{"iopub.status.busy":"2023-03-19T18:52:28.338021Z","iopub.execute_input":"2023-03-19T18:52:28.338282Z","iopub.status.idle":"2023-03-19T18:53:11.888506Z","shell.execute_reply.started":"2023-03-19T18:52:28.338256Z","shell.execute_reply":"2023-03-19T18:53:11.887407Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (‚Ä¶)olve/main/vocab.json:   0%|          | 0.00/1.71M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"787c191701f4465e888efef7a197f6b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (‚Ä¶)olve/main/merges.txt:   0%|          | 0.00/1.27M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57b2390f57644ae4bd61be083c28655f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9597c2ed32144c609f57b69bb7061956"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (‚Ä¶)\"pytorch_model.bin\";:   0%|          | 0.00/551M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e684750ef9fb497da8b73d66cf6b7c56"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TextDataset, DataCollatorForLanguageModeling\n\ntrain_path = '/kaggle/input/toxic-comments/some_text.txt'","metadata":{"execution":{"iopub.status.busy":"2023-03-19T18:53:11.890355Z","iopub.execute_input":"2023-03-19T18:53:11.892936Z","iopub.status.idle":"2023-03-19T18:53:12.655630Z","shell.execute_reply.started":"2023-03-19T18:53:11.892857Z","shell.execute_reply":"2023-03-19T18:53:12.654728Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"with open(train_path, 'r') as f: #open the file\n    contents = f.readlines() #put the lines to a variable (list).","metadata":{"execution":{"iopub.status.busy":"2023-03-19T18:53:12.658513Z","iopub.execute_input":"2023-03-19T18:53:12.658952Z","iopub.status.idle":"2023-03-19T18:53:12.695619Z","shell.execute_reply.started":"2023-03-19T18:53:12.658910Z","shell.execute_reply":"2023-03-19T18:53:12.694720Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# –í–∏–¥ –¥–∞–Ω–Ω—ã—Ö","metadata":{}},{"cell_type":"code","source":"contents[:5]","metadata":{"execution":{"iopub.status.busy":"2023-03-19T19:57:50.390601Z","iopub.execute_input":"2023-03-19T19:57:50.391244Z","iopub.status.idle":"2023-03-19T19:57:50.401378Z","shell.execute_reply.started":"2023-03-19T19:57:50.391204Z","shell.execute_reply":"2023-03-19T19:57:50.400234Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['—Å–∫–æ—Ç–∏–Ω–∞! —á—Ç–æ —Å–∫–∞–∑–∞—Ç—å\\n',\n '—è —Å–µ–≥–æ–¥–Ω—è –ø—Ä–æ–µ–∑–∂–∞–ª–∞ –ø–æ —Ä–∞–±–æ—á–µ–π –∏ –º–µ–∂–¥—É –¥–æ–º–∞–º–∏ —Å–Ω–∏—Ç–µ–Ω–∫–æ –∏ –≥–æ–º–æ–ª—ã—Å–æ–≤–æ–π –º–∞–≥–∞–∑–∏–Ω–æ–º ( –Ω–∞ –ø—É—Å—Ç—ã—Ä–µ) –±–µ–∂–∞–ª–∞ –∫–æ—à–∫–∞ –ø–æ—Ö–æ–∂–µ–≥–æ –æ–∫—Ä–∞—Å–∞. –º–æ–∂–µ—Ç, —è –∏ –æ—à–∏–±–ª–∞—Å—å, –Ω–æ –Ω–µ–æ–±—ã—á–Ω—ã–π –æ–∫—Ä–∞—Å –±—Ä–æ—Å–∏–ª—Å—è –≤ –≥–ª–∞–∑–∞.\\n',\n '–æ—á–µ—Ä–µ–¥–Ω–æ–π –ª–æ—Ö–æ—Ç—Ä–æ–Ω. –∑–∞—á–µ–º –ø—Ä–∏–¥—É–º—ã–≤–∞—Ç—å –æ—á–µ—Ä–µ–¥–Ω–æ–π –Ω–∞–ª–æ–≥ –Ω–∞ –≤–æ–∑–¥—É—Ö, –µ—Å–ª–∏ –º–æ–∂–Ω–æ –æ–±—å—è–≤–∏—Ç—å –∏–Ω—Å—É–ª—å—Ç –∏ –≥—Ä–∏–ø–ø- –ø–∞–Ω–¥–µ–º–∏–µ–π! –∏ –ª–∏—Ö–æ –Ω–∞ –ø—Ä–∏–¥—É—Ä–∫–∞—Ö –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –≥–æ–¥–∞–º–∏ –Ω–∞ —à—Ç—Ä–∞—Ñ–∞—Ö, —Ñ–µ–π–∫–æ–≤—ã—Ö –≤–∞–∫—Ü–∏–Ω–∞—Ö, –≤—Å–µ–≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø–ª–∞—Ç–Ω—ã—Ö —Ç–µ—Å—Ç–∞—Ö, –ø—Ä–æ–¥–∞–∂–µ–π –º–∞—Å–æ–∫ –∏ –ø–µ—Ä—á–∞—Ç–æ–∫ –ø–æ –±–∞—Å–Ω–æ—Å–ª–æ–≤–Ω—ã–º —Ü–µ–Ω–∞–º.. —Å–∞–º–æ–µ —Å–º–µ—à–Ω–æ–µ, —á—Ç–æ –±–∞—Ä–∞–Ω—ã –±–ª–µ—é—Ç –∏ –≤–µ—Ä—è—Ç –ø–∞—Å—Ç—É—Ö—É, —Ç–µ–ª–µ–≤–∏–∑–æ—Ä—É. –∂–∏–≤—É—Ç –∫–∞–∫ –ø–æ–¥ –≥–∏–ø–Ω–æ–∑–æ–º. –Ω–µ –¥—É–º–∞—è, –Ω–µ –≥–ª—è–¥—è –ø–æ —Å—Ç–æ—Ä–æ–Ω–∞–º.\\n',\n '—Ä–µ—Ç—Ä–æ –¥–µ–∂–∞–≤—é ... —Å–ª–æ–∂–Ω–æ –ø–æ–Ω—è—Ç—å —á—É–∂–æ–µ —Å–µ—Ä–¥—Ü–µ , –ª–∏—à –æ—â—É—Ç–∏—Ç—å –º—É–∑—ã–∫–æ–π –≤–∏–¥–∏–º–æ\\n',\n '–∞ –∫–æ–≥–¥–∞ –º—ã —Å—Ç–∞—Ç—É—Å –∞–≥—Ä–æ–≥–æ—Ä–æ–¥–∫–∞ –ø–æ–ª—É—á–∏–ª–∏?\\n']"},"metadata":{}}]},{"cell_type":"markdown","source":"# –ö–æ–ª-–≤–æ –¥–∞–Ω–Ω—ã—Ö","metadata":{}},{"cell_type":"code","source":"len(contents)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T20:17:19.691268Z","iopub.execute_input":"2023-03-19T20:17:19.691997Z","iopub.status.idle":"2023-03-19T20:17:19.704328Z","shell.execute_reply.started":"2023-03-19T20:17:19.691956Z","shell.execute_reply":"2023-03-19T20:17:19.702240Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"10000"},"metadata":{}}]},{"cell_type":"code","source":"path_datatrain = '/kaggle/working/toxic_comments.txt' # –¥–ª—è –∫–∞–≥–≥–ª–∞","metadata":{"execution":{"iopub.status.busy":"2023-03-19T18:53:12.696888Z","iopub.execute_input":"2023-03-19T18:53:12.697225Z","iopub.status.idle":"2023-03-19T18:53:12.702711Z","shell.execute_reply.started":"2023-03-19T18:53:12.697189Z","shell.execute_reply":"2023-03-19T18:53:12.701562Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"with open(path_datatrain, \"w\", encoding=\"utf-8\") as traindata:\n    for sentence in contents:\n        traindata.writelines(sentence)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T18:53:12.704269Z","iopub.execute_input":"2023-03-19T18:53:12.704979Z","iopub.status.idle":"2023-03-19T18:53:12.845529Z","shell.execute_reply.started":"2023-03-19T18:53:12.704941Z","shell.execute_reply":"2023-03-19T18:53:12.844671Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\ntrain_dataset = TextDataset(tokenizer=tokenizer,file_path=path_datatrain,block_size=64, \n                            overwrite_cache=True)\n\n# —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –ø–æ–¥–∞–≤–∞—Ç—å –≤ –º–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã–µ –≤ –Ω—É–∂–Ω–æ–º –µ–π –≤–∏–¥–µ\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)","metadata":{"id":"hA-5Tfk-3u66","execution":{"iopub.status.busy":"2023-03-19T18:53:12.846785Z","iopub.execute_input":"2023-03-19T18:53:12.847204Z","iopub.status.idle":"2023-03-19T18:53:18.437768Z","shell.execute_reply.started":"2023-03-19T18:53:12.847168Z","shell.execute_reply":"2023-03-19T18:53:18.436743Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments( \n    output_dir= \"./finetuned\",\n    overwrite_output_dir=True,\n    num_train_epochs=100, \n    per_device_train_batch_size=64, \n    per_device_eval_batch_size=64,  \n    )\n\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n    optimizers = (torch.optim.AdamW(model.parameters(),lr=1e-5),None))","metadata":{"id":"DBvwqvKj4CC-","execution":{"iopub.status.busy":"2023-03-19T18:53:18.439123Z","iopub.execute_input":"2023-03-19T18:53:18.439567Z","iopub.status.idle":"2023-03-19T18:53:19.112536Z","shell.execute_reply.started":"2023-03-19T18:53:18.439524Z","shell.execute_reply":"2023-03-19T18:53:19.111482Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"-J75a0_I4F7t","execution":{"iopub.status.busy":"2023-03-19T18:53:19.114035Z","iopub.execute_input":"2023-03-19T18:53:19.114793Z","iopub.status.idle":"2023-03-19T19:52:04.463758Z","shell.execute_reply.started":"2023-03-19T18:53:19.114752Z","shell.execute_reply":"2023-03-19T19:52:04.462812Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"***** Running training *****\n  Num examples = 3390\n  Num Epochs = 100\n  Instantaneous batch size per device = 64\n  Total train batch size (w. parallel, distributed & accumulation) = 128\n  Gradient Accumulation steps = 1\n  Total optimization steps = 2700\n  Number of trainable parameters = 125231616\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.13.10"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230319_185340-qspzmq5h</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/otpravlyaj-golubej/huggingface/runs/qspzmq5h' target=\"_blank\">polished-firebrand-6</a></strong> to <a href='https://wandb.ai/otpravlyaj-golubej/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/otpravlyaj-golubej/huggingface' target=\"_blank\">https://wandb.ai/otpravlyaj-golubej/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/otpravlyaj-golubej/huggingface/runs/qspzmq5h' target=\"_blank\">https://wandb.ai/otpravlyaj-golubej/huggingface/runs/qspzmq5h</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2700' max='2700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2700/2700 57:44, Epoch 100/100]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>4.318900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.818800</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>3.507200</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>3.300200</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>3.182800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to ./finetuned/checkpoint-500\nConfiguration saved in ./finetuned/checkpoint-500/config.json\nConfiguration saved in ./finetuned/checkpoint-500/generation_config.json\nModel weights saved in ./finetuned/checkpoint-500/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./finetuned/checkpoint-1000\nConfiguration saved in ./finetuned/checkpoint-1000/config.json\nConfiguration saved in ./finetuned/checkpoint-1000/generation_config.json\nModel weights saved in ./finetuned/checkpoint-1000/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./finetuned/checkpoint-1500\nConfiguration saved in ./finetuned/checkpoint-1500/config.json\nConfiguration saved in ./finetuned/checkpoint-1500/generation_config.json\nModel weights saved in ./finetuned/checkpoint-1500/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./finetuned/checkpoint-2000\nConfiguration saved in ./finetuned/checkpoint-2000/config.json\nConfiguration saved in ./finetuned/checkpoint-2000/generation_config.json\nModel weights saved in ./finetuned/checkpoint-2000/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./finetuned/checkpoint-2500\nConfiguration saved in ./finetuned/checkpoint-2500/config.json\nConfiguration saved in ./finetuned/checkpoint-2500/generation_config.json\nModel weights saved in ./finetuned/checkpoint-2500/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2700, training_loss=3.5898939344618057, metrics={'train_runtime': 3525.3092, 'train_samples_per_second': 96.162, 'train_steps_per_second': 0.766, 'total_flos': 1.1072249856e+16, 'train_loss': 3.5898939344618057, 'epoch': 100.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"TrainOutput(global_step=2700, training_loss=3.5898939344618057, metrics={'train_runtime': 3525.3092, 'train_samples_per_second': 96.162, 'train_steps_per_second': 0.766, 'total_flos': 1.1072249856e+16, 'train_loss': 3.5898939344618057, 'epoch': 100.0})","metadata":{}},{"cell_type":"code","source":"text = \"–ú–æ–π –¥—Ä—É–≥ –Ω–∞–ø–∏—Å–∞–ª –∫–Ω–∏–≥—É\"\ninput_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\nmodel.eval()\nwith torch.no_grad():\n    out = model.generate(input_ids, \n                        do_sample=True,\n                        temperature=0.9,\n                        top_k=30,\n                        max_length=60,\n                        )\n\ngenerated_text = list(map(tokenizer.decode, out))[0]\nprint()\nprint(generated_text)","metadata":{"id":"0Jim6CVN4KS7","execution":{"iopub.status.busy":"2023-03-19T19:52:04.467000Z","iopub.execute_input":"2023-03-19T19:52:04.467736Z","iopub.status.idle":"2023-03-19T19:52:05.559126Z","shell.execute_reply.started":"2023-03-19T19:52:04.467688Z","shell.execute_reply":"2023-03-19T19:52:05.557936Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": false\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n–ú–æ–π –¥—Ä—É–≥ –Ω–∞–ø–∏—Å–∞–ª –∫–Ω–∏–≥—É –ø—Ä–æ –º–µ–Ω—Ç–æ–≤\n–ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ, –Ω–µ —Å—Ä–∞–∑—É, –∫–æ–Ω–µ—á–Ω–æ. –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ, –Ω–æ –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ—Ç—Å—è.\n–∞ —Ç—ã —É–∂–µ –≤ —Å–ø–∏—Å–∫–µ –≤—Ä–∞–≥–æ–≤ —Ä–æ—Å—Å–∏–∏.\n–ø—Ä–∏–≤–µ—Ç–∏–∫) –Ω–µ –ø–æ–º–µ—à–∞–ª –±—ã))\n—Å –¥–Ω–µ–º —Ä–æ–∂–¥–µ–Ω–∏—è, –¥–æ—Ä–æ–≥–∞—è! —Ö–æ—Ä–æ—à–µ–≥–æ –æ—Ç–¥—ã—Ö–∞, –ø—É—Å—Ç—å —Ç–≤–æ–π –º–∞–ª—ã—à —Ä–∞—Å—Ç–µ—Ç —Å—á–∞—Å—Ç–ª–∏–≤—ã–º, –ø—É—Å—Ç—å —É\n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"–í—á–µ—Ä–∞ —è —Å–º–æ—Ç—Ä–µ–ª —Ç–µ–ª–µ–≤–∏–∑–æ—Ä –∏\"\ninput_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\nmodel.eval()\nwith torch.no_grad():\n    out = model.generate(input_ids, \n                        do_sample=True,\n                        temperature=1.4,\n                        top_k=50,\n                        max_length=100,\n                        )\n\ngenerated_text = list(map(tokenizer.decode, out))[0]\nprint()\nprint(generated_text)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T19:56:49.555396Z","iopub.execute_input":"2023-03-19T19:56:49.555773Z","iopub.status.idle":"2023-03-19T19:56:51.011846Z","shell.execute_reply.started":"2023-03-19T19:56:49.555738Z","shell.execute_reply":"2023-03-19T19:56:51.010327Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": false\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n–í—á–µ—Ä–∞ —è —Å–º–æ—Ç—Ä–µ–ª —Ç–µ–ª–µ–≤–∏–∑–æ—Ä –∏ –æ–±—Ä–∞—Ç–∏–ª –Ω–∞ —Å–µ–±—è –≤–Ω–∏–º–∞–Ω–∏–µ,–∫–∞–∫ –±—É–¥—Ç–æ –º–æ–∏ –≥–ª–∞–∑–∞ —Ä–∞–∑—É–ª–∏—Å—å –∏ –Ω–∞—á–∞–ª–∏ —á—Ç–æ-—Ç–æ –≤—ã—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –ø–æ —Å—Ç–æ—Ä–æ–Ω–∞–º......–∞ –≤ –∫–æ–º–Ω–∞—Ç–µ —Å—Ç–æ—è–ª –≥—É–ª –æ—Ç –≥—Ä–æ—Ö–æ—Ç–∞...—ç—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å, –∫–æ–≥–¥–∞ —è —Å—Ç–æ—è–ª –Ω–∞ –±–∞–ª–∫–æ–Ω–µ, –≤ –∫—É—Ö–Ω–µ –∏ –≤–¥—Ä—É–≥ —è –ø–æ—á—É–≤—Å—Ç–≤–æ–≤–∞–ª –¥—É–ª –ø—Ä—è–º–æ –≤ –ª–æ–± —Å—Ç–æ—è–≤—à–µ–π –æ–∫–æ–ª–æ –º–Ω–µ –≤ –∫–æ—Ä–∏–¥–æ—Ä–µ –Ω—è–Ω–µ.\n–∞ –º–Ω–µ —É–∂–µ –≤ 20–ª–µ—Ç –Ω–∞–¥–æ–µ–ª–∏ —ç—Ç–∏ –¥–∏–µ—Ç—ã —Å –Ω–µ–≥–∞—Ç–∏–≤–æ–º\n—É –º–µ–Ω—è —Ç–æ–∂–µ —Å–∞–º–æ–µ. –≤ —Å–∞–¥—É —è–±–ª–æ–∫ –∏ –≥—Ä—É—à –º–Ω–æ–≥–æ, —è –∫–∞–∂–¥—É—é —Å–∫–ª–∞–¥—ã–≤–∞—é –≤ –±–∞–Ω–æ—á–∫—É\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### –ü–æ–ª—É—á–∞–µ—Ç—Å—è –ø–ª–æ—Ö–æ. –£–º–µ–Ω—å—à–∏–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –∏ top_k (—Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å).","metadata":{}},{"cell_type":"code","source":"text = \"–í—á–µ—Ä–∞ —è —Å–º–æ—Ç—Ä–µ–ª —Ç–µ–ª–µ–≤–∏–∑–æ—Ä –∏\"\ninput_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\nmodel.eval()\nwith torch.no_grad():\n    out = model.generate(input_ids, \n                         do_sample=True,\n                         temperature=0.2,\n                         top_k=20,\n                         max_length=50,\n                        )\n\ngenerated_text = list(map(tokenizer.decode, out))[0]\nprint()\nprint(generated_text)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T19:59:12.205208Z","iopub.execute_input":"2023-03-19T19:59:12.205640Z","iopub.status.idle":"2023-03-19T19:59:12.954601Z","shell.execute_reply.started":"2023-03-19T19:59:12.205595Z","shell.execute_reply":"2023-03-19T19:59:12.953282Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": false\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n–í—á–µ—Ä–∞ —è —Å–º–æ—Ç—Ä–µ–ª —Ç–µ–ª–µ–≤–∏–∑–æ—Ä –∏ –¥—É–º–∞–ª, —á—Ç–æ –∂–µ —è —Ç–∞–∫–æ–≥–æ –Ω–µ —Å–¥–µ–ª–∞–ª? –≤–µ–¥—å —è –∂–µ –Ω–µ –≤–∏–Ω–æ–≤–∞—Ç, —á—Ç–æ —É –º–µ–Ω—è –Ω–µ—Ç –º–∞—à–∏–Ω—ã, –∏ —è –Ω–µ –≥—É–ª—è–ª –Ω–∞ —É–ª–∏—Ü–µ. —è –ø—Ä–æ—Å—Ç–æ –Ω–µ –∑–Ω–∞–ª, —á—Ç–æ –º–Ω–µ –¥–µ–ª–∞—Ç—å. –≤–µ–¥—å —è –∂–µ –Ω–µ –≤–∏–Ω–æ–≤–∞—Ç, —á—Ç–æ\n","output_type":"stream"}]},{"cell_type":"markdown","source":"–ê —Ç–∞–∫ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–µ –Ω–∞ –æ–¥–Ω–∏—Ö –∏ —Ç–µ—Ö –∂–µ —Å–ª–æ–≤–∞—Ö.","metadata":{}},{"cell_type":"code","source":"text = \"–í—á–µ—Ä–∞ —è —Å–º–æ—Ç—Ä–µ–ª —Ç–µ–ª–µ–≤–∏–∑–æ—Ä –∏\"\ninput_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\nmodel.eval()\nwith torch.no_grad():\n    out = model.generate(input_ids, \n                        do_sample=True,\n                        temperature=1.4,\n                        top_k=20,\n                        max_length=100,\n                        )\n\ngenerated_text = list(map(tokenizer.decode, out))[0]\nprint()\nprint(generated_text)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T20:05:22.141161Z","iopub.execute_input":"2023-03-19T20:05:22.141533Z","iopub.status.idle":"2023-03-19T20:05:23.879877Z","shell.execute_reply.started":"2023-03-19T20:05:22.141498Z","shell.execute_reply":"2023-03-19T20:05:23.878693Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": false\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n–í—á–µ—Ä–∞ —è —Å–º–æ—Ç—Ä–µ–ª —Ç–µ–ª–µ–≤–∏–∑–æ—Ä –∏ –≤—Å–ø–æ–º–Ω–∏–ª –æ–¥–∏–Ω —Å—é–∂–µ—Ç –∫–æ—Ç–æ—Ä—ã–π –º–Ω–µ –∑–∞–¥–∞–ª–∞ –æ–¥–Ω–∞ –º–æ—è –∑–Ω–∞–∫–æ–º–∞—è- –æ–Ω–∞ –ø—Ä–∏–µ–∑–∂–∞–ª–∞ –Ω–∞ –ª–µ—Ç–æ –∫ –ø–æ–¥—Ä—É–≥–µ –æ—Ç–¥—ã—Ö–∞—Ç—å –∫ –Ω–µ–π –∞ —Ç–∞–º –æ–¥–Ω–∞ –∏–∑ –Ω–∏—Ö –ø—å—è–Ω–∞—è –Ω–∞ —Ç—Ä–∞—É–ª–µ–µ—Ä–µ –∫–∞—Ç–∞–ª–∞—Å—å –ø–æ –∫–∞–∫–∏–º —Ç–æ —É–ª–∏—Ü–∞–º –Ω–∞ –±–µ–ª–æ–π –º–∞—à–∏–Ω–µ. —ç—Ç–æ —Ç–æ—á–Ω–æ –æ–Ω–∞! —É –Ω–µ–µ –≤ —Ç–æ—Ç –≤–µ—á–µ—Ä –±—ã–ª–æ –Ω–µ —Ö–æ—Ä–æ—à–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏ –æ–Ω–∞ –ø—Ä–∏–≥–ª–∞—Å–∏–ª–∞ –Ω–∞ —É–∂–∏–Ω –∑–Ω–∞–∫–æ–º–æ–≥–æ –æ–Ω–∞ –ø—Ä–∏—à–ª–∞ –∏ –≤—ã–ø–∏–ª–∞ —Å –Ω–∏–º –Ω–µ–º–Ω–æ–≥–æ..–∞ –≤ –µ—ë —Ç–µ–ª–µ—Ñ–æ–Ω–µ –≤ —ç—Ç–æ—Ç –º–æ–º–µ–Ω—Ç –Ω–µ –±—ã–ª–æ –Ω–æ–º–µ—Ä–∞ –µ—ë –º—É–∂–∞, –æ–Ω–∞ –≤–∏–¥–∏–º–æ –µ–≥–æ –∑–∞–ø–æ–º–Ω–∏–ª–∞... –≤–æ—Ç —Ç–∞–∫–∞—è –∏–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è —Å—É–¥—å–±–∞...ÔøΩ\n","output_type":"stream"}]},{"cell_type":"markdown","source":"–ü–æ–ª—É—á–∏–ª–∞—Å—å –∫–æ—Ä–æ—Ç–∫–∞—è —Å—Ç—Ä–∞–Ω–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è. –ì–ª—É–ø–∞—è, –Ω–æ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å–≤—è–∑–Ω–∞—è.","metadata":{}},{"cell_type":"code","source":"text = \"–£ –º–µ–Ω—è –æ—Ç–µ—Ü —Ä–∞–±–æ—Ç–∞–µ—Ç \"\ninput_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\nmodel.eval()\nwith torch.no_grad():\n    out = model.generate(input_ids, \n                        do_sample=True,\n                        temperature=1.4,\n                        top_k=20,\n                        max_length=100,\n                        )\n\ngenerated_text = list(map(tokenizer.decode, out))[0]\nprint()\nprint(generated_text)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T20:07:20.627944Z","iopub.execute_input":"2023-03-19T20:07:20.628323Z","iopub.status.idle":"2023-03-19T20:07:22.069444Z","shell.execute_reply.started":"2023-03-19T20:07:20.628283Z","shell.execute_reply":"2023-03-19T20:07:22.068163Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": false\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n–£ –º–µ–Ω—è –æ—Ç–µ—Ü —Ä–∞–±–æ—Ç–∞–µ—Ç!! —è –µ–≥–æ –æ—á–µ–Ω—å —É–≤–∞–∂–∞—é!!!\n–≤—ã –ø—Ä–æ—Å—Ç–æ –∫–ª–∞—Å—Å‚ò∫Ô∏èÔ∏è üëçü§™\n—ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ –∫—Ä–∞—Å–∏–≤–æ –∏ –∫—Ä–∞—Å–∏–≤–æ, —ç—Ç–æ –≤–µ–ª–∏–∫–æ–ª–µ–ø–Ω–æ!\n–≤–µ–∑–¥–µ –ª—é–¥–∏ —Ä–∞–±–æ—Ç–∞—é—Ç,–∞ –Ω–µ –±–æ–ª—Ç–∞—é—Ç—Å—è –∑–∞ —Å—á—ë—Ç –ø—Ä–æ—Å—Ç—ã—Ö –ª—é–¥–µ–π!\n–æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ –≤—ã –Ω–∞–ø–∏—Å–∞–ª–∏, —á—Ç–æ —É –Ω–∏—Ö –µ—Å—Ç—å –º–æ–∑–≥–∏...))) –∞ –≤—ã –∏—Ö –≥–¥–µ –±–µ—Ä–µ—Ç–µ????\n—ç—Ç–æ –Ω–µ —Ä–∞–∑–≤–æ–¥ –∞ –ø—Ä–æ–≤–æ–∫–∞—Ü–∏—è(tr) (tr)\n–Ω–∞–ø–∏—à–∏—Ç–µ –≤ —Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫—É –µ—Å–ª–∏\n","output_type":"stream"}]},{"cell_type":"markdown","source":"–¢—É—Ç —É–∂–µ –ø–æ—Ö—É–∂–µ. –ù–æ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –æ—á–µ–≤–∏–¥–Ω–æ, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ, –Ω–∞–≤–µ—Ä–Ω–æ–µ, –Ω–µ –æ—á–µ–Ω—å –ø–æ–¥—Ö–æ–¥—è—Ç –ø–æ–¥ –∑–∞–¥–∞—á—É -- –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –¥–æ–≤–æ–ª—å–Ω–æ \"–±–µ—Å—Å–≤—è–∑–Ω—ã\" –∏ –º–æ–¥–µ–ª—å –∏–º –∏ –ø–æ–¥—Ä–∞–∂–∞–µ—Ç.","metadata":{}},{"cell_type":"markdown","source":"Num Beams –æ–ø–µ—Ä–∏—Ä—É–µ—Ç —Å–º–∞–π–ª–∏–∫–∞–º–∏\n","metadata":{}},{"cell_type":"code","source":"text = \"–£ –º–µ–Ω—è –æ—Ç–µ—Ü —Ä–∞–±–æ—Ç–∞–µ—Ç \"\ninput_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\nmodel.eval()\nwith torch.no_grad():\n    out = model.generate(input_ids, \n                        do_sample=False, num_beams=5,\n                        max_length=100,\n                        )\n\ngenerated_text = list(map(tokenizer.decode, out))[0]\nprint()\nprint(generated_text)\nnum_beams=10,","metadata":{"execution":{"iopub.status.busy":"2023-03-19T20:16:49.839879Z","iopub.execute_input":"2023-03-19T20:16:49.840472Z","iopub.status.idle":"2023-03-19T20:16:52.497420Z","shell.execute_reply.started":"2023-03-19T20:16:49.840426Z","shell.execute_reply":"2023-03-19T20:16:52.496174Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": false\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n–£ –º–µ–Ω—è –æ—Ç–µ—Ü —Ä–∞–±–æ—Ç–∞–µ—Ç üíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãüíãÔøΩ\n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"–ö–∞–∂–¥—ã–π –¥–µ–Ω—å —è \"\ninput_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\nmodel.eval()\nwith torch.no_grad():\n    out = model.generate(input_ids, \n                        do_sample=False, num_beams=15,\n                        max_length=50,\n                        )\n\ngenerated_text = list(map(tokenizer.decode, out))[0]\nprint()\nprint(generated_text)\nnum_beams=10,","metadata":{"execution":{"iopub.status.busy":"2023-03-19T20:16:03.457849Z","iopub.execute_input":"2023-03-19T20:16:03.458891Z","iopub.status.idle":"2023-03-19T20:16:05.263726Z","shell.execute_reply.started":"2023-03-19T20:16:03.458830Z","shell.execute_reply":"2023-03-19T20:16:05.262630Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": false\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n–ö–∞–∂–¥—ã–π –¥–µ–Ω—å —è ü§¶ü§¶ü§¶ü§¶ü§¶ü§¶ü§¶ü§¶ü§¶ü§¶ü§¶ü§¶ü§¶ü§¶ü§¶ÔøΩ\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### –ó–∞–¥–∞–Ω–∏–µ  2 (2 –±–∞–ª–ª–∞)\n\n–û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã:\n\n1) –í –∫–∞–∫–∏—Ö —Å—Ç–∞—Ç—å—è –±—ã–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã GPT-1, GPT-2, GPT-3?\n\n2) –ö–∞–∫ —Å–æ–±–∏—Ä–∞–ª—Å—è –æ–±—É—á–∞—é—â–∏–π –∫–æ—Ä–ø—É—Å –¥–ª—è GPT-3? –ö–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º —Å–æ–∑–¥–∞—Ç–µ–ª–∏ —Å—Ç–∞—Ä–∞–ª–∏—Å—å –æ–±–µ—Å–ø–µ—á–∏—Ç—å –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–æ–≤ –≤ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ?","metadata":{"id":"ae8437e8"}},{"cell_type":"markdown","source":"1. GPT-1 paper Improving Language Understanding by Generative Pre-training.\n\n2. GPT-2 paper Language Models are unsupervised multitask learners.\n\n3. GPT-3 paper Language models are few shot learners.","metadata":{}},{"cell_type":"markdown","source":"–ö—Ä–∞—Ç–∫–æ:\n\nGPT-3 –±—ã–ª –æ–±—É—á–µ–Ω –Ω–∞ –ø—è—Ç–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–æ—Ä–ø—É—Å–∞—Ö, –∫–∞–∂–¥–æ–º—É –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –±—ã–ª –ø—Ä–∏—Å–≤–æ–µ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –≤–µ—Å. –ù–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–±–∏—Ä–∞–ª–∏—Å—å —á–∞—â–µ, –∏ –º–æ–¥–µ–ª—å –æ–±—É—á–∞–ª–∞—Å—å –Ω–∞ –Ω–∏—Ö –≤ —Ç–µ—á–µ–Ω–∏–µ –±–æ–ª–µ–µ —á–µ–º –æ–¥–Ω–æ–π —ç–ø–æ—Ö–∏. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –¥–∞—Ç–∞—Å–µ—Ç—ã: Common Crawl, WebText, Books1, Books2 –∏ Wikipedia.\n\n–ü–æ–¥—Ä–æ–±–Ω–µ–µ: \n\n–ß—Ç–æ–±—ã —É–ª—É—á—à–∏—Ç—å —Å—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö, —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–¥–µ–ª–∞–ª–∏ —Å–ª–µ–¥—É—é—â–µ–µ:\n\n* –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–ª–∏ –≤–µ—Ä—Å–∏—é CommonCrawl –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ —Å —Ä—è–¥–æ–º –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –∫–æ—Ä–ø—É—Å–æ–≤;\n* –≤—ã–ø–æ–ª–Ω–∏–ª–∏ –Ω–µ—á–µ—Ç–∫—É—é –¥–µ–¥—É–±–ª–∏–∫–∞—Ü–∏—é –Ω–∞ —É—Ä–æ–≤–Ω–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–≤–Ω—É—Ç—Ä–∏) –∏ –º–µ–∂–¥—É –Ω–∞–±–æ—Ä–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–∏–º–µ–Ω—è–µ–º–æ–≥–æ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è;\n* –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –¥–æ–±–∞–≤–∏–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –∫–æ—Ä–ø—É—Å–∞ –≤ –Ω–∞–±–æ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: WebText, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Ç–µ–∫—Å—Ç—ã —Å —Å–∞–π—Ç–æ–≤, —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–æ—Ç–æ—Ä—ã—Ö –±—ã–ª–∏ –æ—Ç–º–µ—á–µ–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏, –∫–∞–∫ –ø–æ–ª–µ–∑–Ω—ã–µ –ø–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É; –∫–æ—Ä–ø—É—Å–∞ –∫–Ω–∏–≥ Books1 –∏ Books2; –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—É—é –í–∏–∫–∏–ø–µ–¥–∏—é.\n\n–í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –æ—Ç–±–∏—Ä–∞–ª–∏—Å—å –Ω–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∏—Ö —Ä–∞–∑–º–µ—Ä—É. –ë–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –Ω–∞–±–æ—Ä—ã –≤—ã–±–∏—Ä–∞–ª–∏—Å—å —á–∞—â–µ, —Ç–∞–∫ —á—Ç–æ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö Common Crawl –∏ Books2 –≤—ã–±–∏—Ä–∞–ª–∏—Å—å –º–µ–Ω–µ–µ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è, –∞ –¥—Ä—É–≥–∏–µ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –æ—Ç–±–∏—Ä–∞–ª–∏—Å—å –ø–æ 2‚Äì3 —Ä–∞–∑–∞.","metadata":{}}]}