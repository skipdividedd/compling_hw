{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a85e8c0",
   "metadata": {
    "id": "13efba76",
    "papermill": {
     "duration": 0.009344,
     "end_time": "2023-03-26T15:03:32.907997",
     "exception": false,
     "start_time": "2023-03-26T15:03:32.898653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Домашнее задание № 11. Машинный перевод\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926e18ea",
   "metadata": {
    "papermill": {
     "duration": 0.008359,
     "end_time": "2023-03-26T15:03:32.924556",
     "exception": false,
     "start_time": "2023-03-26T15:03:32.916197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Для данных en-de."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728c90d1",
   "metadata": {
    "id": "e384bd5c",
    "papermill": {
     "duration": 0.008322,
     "end_time": "2023-03-26T15:03:36.054103",
     "exception": false,
     "start_time": "2023-03-26T15:03:36.045781",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Транформеры для решения seq2seq задач"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f8f998",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:03:36.072487Z",
     "iopub.status.busy": "2023-03-26T15:03:36.072161Z",
     "iopub.status.idle": "2023-03-26T15:03:39.450404Z",
     "shell.execute_reply": "2023-03-26T15:03:39.449351Z"
    },
    "id": "947b3313",
    "papermill": {
     "duration": 3.39084,
     "end_time": "2023-03-26T15:03:39.453302",
     "exception": false,
     "start_time": "2023-03-26T15:03:36.062462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2ced16",
   "metadata": {
    "id": "018d83aa",
    "papermill": {
     "duration": 0.009139,
     "end_time": "2023-03-26T15:03:39.472541",
     "exception": false,
     "start_time": "2023-03-26T15:03:39.463402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Данные взяты вот отсюда - https://opus.nlpl.eu/opus-100.php (раздел с отдельными языковыми парами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba8e8b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:03:39.492384Z",
     "iopub.status.busy": "2023-03-26T15:03:39.491790Z",
     "iopub.status.idle": "2023-03-26T15:03:42.986825Z",
     "shell.execute_reply": "2023-03-26T15:03:42.985663Z"
    },
    "id": "e110ff04",
    "papermill": {
     "duration": 3.507893,
     "end_time": "2023-03-26T15:03:42.989597",
     "exception": false,
     "start_time": "2023-03-26T15:03:39.481704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_sents = open('/kaggle/input/opus-tr/opus.de-en-train.en').read().splitlines()\n",
    "de_sents = open('/kaggle/input/opus-tr/opus.de-en-train.de').read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d6315",
   "metadata": {
    "id": "c009c96e",
    "papermill": {
     "duration": 0.008281,
     "end_time": "2023-03-26T15:03:43.006685",
     "exception": false,
     "start_time": "2023-03-26T15:03:42.998404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Пример перевода с английского на немецкий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d533c192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:03:43.025439Z",
     "iopub.status.busy": "2023-03-26T15:03:43.024840Z",
     "iopub.status.idle": "2023-03-26T15:03:43.032240Z",
     "shell.execute_reply": "2023-03-26T15:03:43.031251Z"
    },
    "id": "0eb9b498",
    "outputId": "f35d810c-2be3-41f8-fb43-0e40e6a98ac1",
    "papermill": {
     "duration": 0.019773,
     "end_time": "2023-03-26T15:03:43.034953",
     "exception": false,
     "start_time": "2023-03-26T15:03:43.015180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I am not talking about criminalising it or reacting to it emotionally, but we must tackle this subject.',\n",
       " 'Es geht nicht darum, hier zu kriminalisieren, zu emotionalisieren, sondern wir müssen uns mit dem Thema auseinandersetzen.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sents[-1], de_sents[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b77aa",
   "metadata": {
    "id": "c39921c4",
    "papermill": {
     "duration": 0.008333,
     "end_time": "2023-03-26T15:03:43.051867",
     "exception": false,
     "start_time": "2023-03-26T15:03:43.043534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Как обычно нам нужен токенизатор, а точнее даже 2, т.к. у нас два корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e9cbbc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:03:43.070461Z",
     "iopub.status.busy": "2023-03-26T15:03:43.069621Z",
     "iopub.status.idle": "2023-03-26T15:06:32.546436Z",
     "shell.execute_reply": "2023-03-26T15:06:32.545319Z"
    },
    "id": "4b79b4da",
    "papermill": {
     "duration": 169.490764,
     "end_time": "2023-03-26T15:06:32.550982",
     "exception": false,
     "start_time": "2023-03-26T15:03:43.060218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer_en = Tokenizer(BPE())\n",
    "tokenizer_en.pre_tokenizer = Whitespace()\n",
    "trainer_en = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "tokenizer_en.train(files=[\"/kaggle/input/opus-tr/opus.de-en-train.en\"], trainer=trainer_en)\n",
    "\n",
    "tokenizer_de = Tokenizer(BPE())\n",
    "tokenizer_de.pre_tokenizer = Whitespace()\n",
    "trainer_de = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "tokenizer_de.train(files=[\"/kaggle/input/opus-tr/opus.de-en-train.de\"], trainer=trainer_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed618650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:06:32.572607Z",
     "iopub.status.busy": "2023-03-26T15:06:32.572279Z",
     "iopub.status.idle": "2023-03-26T15:06:32.615091Z",
     "shell.execute_reply": "2023-03-26T15:06:32.613693Z"
    },
    "id": "0dd90665",
    "papermill": {
     "duration": 0.056992,
     "end_time": "2023-03-26T15:06:32.617349",
     "exception": false,
     "start_time": "2023-03-26T15:06:32.560357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer_en.save('/kaggle/working/tokenizer_en')\n",
    "tokenizer_de.save('/kaggle/working/tokenizer_de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab24610a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:06:32.636831Z",
     "iopub.status.busy": "2023-03-26T15:06:32.636512Z",
     "iopub.status.idle": "2023-03-26T15:06:32.756584Z",
     "shell.execute_reply": "2023-03-26T15:06:32.755501Z"
    },
    "id": "0e0f7f77",
    "papermill": {
     "duration": 0.132919,
     "end_time": "2023-03-26T15:06:32.759448",
     "exception": false,
     "start_time": "2023-03-26T15:06:32.626529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer.from_file(\"/kaggle/working/tokenizer_en\")\n",
    "tokenizer_de = Tokenizer.from_file(\"/kaggle/working/tokenizer_de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d2b15ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:06:32.785808Z",
     "iopub.status.busy": "2023-03-26T15:06:32.785472Z",
     "iopub.status.idle": "2023-03-26T15:06:32.790583Z",
     "shell.execute_reply": "2023-03-26T15:06:32.789479Z"
    },
    "id": "dc003758",
    "papermill": {
     "duration": 0.024205,
     "end_time": "2023-03-26T15:06:32.792951",
     "exception": false,
     "start_time": "2023-03-26T15:06:32.768746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode(text, tokenizer, max_len):\n",
    "    return [tokenizer.token_to_id('[CLS]')] + tokenizer.encode(text).ids[:max_len] + [tokenizer.token_to_id('[SEP]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b791879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:06:32.811987Z",
     "iopub.status.busy": "2023-03-26T15:06:32.811695Z",
     "iopub.status.idle": "2023-03-26T15:06:32.817779Z",
     "shell.execute_reply": "2023-03-26T15:06:32.816697Z"
    },
    "id": "96920fdc",
    "papermill": {
     "duration": 0.017869,
     "end_time": "2023-03-26T15:06:32.819879",
     "exception": false,
     "start_time": "2023-03-26T15:06:32.802010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# важно следить чтобы индекс паддинга совпадал в токенизаторе с value в pad_sequences\n",
    "PAD_IDX = tokenizer_de.token_to_id('[PAD]')\n",
    "PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51b2e6f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:06:32.839758Z",
     "iopub.status.busy": "2023-03-26T15:06:32.838866Z",
     "iopub.status.idle": "2023-03-26T15:06:32.843686Z",
     "shell.execute_reply": "2023-03-26T15:06:32.842811Z"
    },
    "id": "5cc0a376",
    "papermill": {
     "duration": 0.01697,
     "end_time": "2023-03-26T15:06:32.845724",
     "exception": false,
     "start_time": "2023-03-26T15:06:32.828754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (разные чтобы показать что в seq2seq не нужна одинаковая длина)\n",
    "max_len_en, max_len_de = 40, 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a21af9a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:06:32.867241Z",
     "iopub.status.busy": "2023-03-26T15:06:32.865402Z",
     "iopub.status.idle": "2023-03-26T15:07:46.412447Z",
     "shell.execute_reply": "2023-03-26T15:07:46.411367Z"
    },
    "id": "7fc2dae1",
    "papermill": {
     "duration": 73.560269,
     "end_time": "2023-03-26T15:07:46.415092",
     "exception": false,
     "start_time": "2023-03-26T15:06:32.854823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_en = [encode(t, tokenizer_en, max_len_en) for t in en_sents]\n",
    "X_de = [encode(t, tokenizer_de, max_len_de) for t in de_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75fd5cb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:07:46.436155Z",
     "iopub.status.busy": "2023-03-26T15:07:46.435830Z",
     "iopub.status.idle": "2023-03-26T15:07:46.442109Z",
     "shell.execute_reply": "2023-03-26T15:07:46.441143Z"
    },
    "id": "0560e01f",
    "papermill": {
     "duration": 0.019698,
     "end_time": "2023-03-26T15:07:46.444167",
     "exception": false,
     "start_time": "2023-03-26T15:07:46.424469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 1000000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# миллион примеров \n",
    "len(X_en), len(X_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bdd4bc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:07:46.464106Z",
     "iopub.status.busy": "2023-03-26T15:07:46.463301Z",
     "iopub.status.idle": "2023-03-26T15:07:46.470865Z",
     "shell.execute_reply": "2023-03-26T15:07:46.470000Z"
    },
    "id": "7634853b",
    "papermill": {
     "duration": 0.020083,
     "end_time": "2023-03-26T15:07:46.473244",
     "exception": false,
     "start_time": "2023-03-26T15:07:46.453161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, texts_en, texts_de):\n",
    "        self.texts_en = [torch.LongTensor(sent) for sent in texts_en]\n",
    "        self.texts_en = torch.nn.utils.rnn.pad_sequence(self.texts_en, padding_value=PAD_IDX)\n",
    "        \n",
    "        self.texts_de = [torch.LongTensor(sent) for sent in texts_de]\n",
    "        self.texts_de = torch.nn.utils.rnn.pad_sequence(self.texts_de, padding_value=PAD_IDX)\n",
    "\n",
    "        self.length = len(texts_en)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        ids_en = self.texts_en[:, index]\n",
    "        ids_de = self.texts_de[:, index]\n",
    "\n",
    "        return ids_en, ids_de"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c592b2",
   "metadata": {
    "id": "ec889a8d",
    "papermill": {
     "duration": 0.008681,
     "end_time": "2023-03-26T15:07:46.490822",
     "exception": false,
     "start_time": "2023-03-26T15:07:46.482141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "трейн и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "453379a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:07:46.510373Z",
     "iopub.status.busy": "2023-03-26T15:07:46.509793Z",
     "iopub.status.idle": "2023-03-26T15:07:46.684232Z",
     "shell.execute_reply": "2023-03-26T15:07:46.683211Z"
    },
    "id": "9c9eaf09",
    "papermill": {
     "duration": 0.187167,
     "end_time": "2023-03-26T15:07:46.686809",
     "exception": false,
     "start_time": "2023-03-26T15:07:46.499642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_en_train, X_de_train = X_en, X_de\n",
    "en_sents_valid = open('/kaggle/input/opus-tr/opus.de-en-dev.en').read().splitlines()\n",
    "de_sents_valid = open('/kaggle/input/opus-tr/opus.de-en-dev.de').read().splitlines()\n",
    "X_en_valid = [encode(t, tokenizer_en, max_len_en) for t in en_sents_valid]\n",
    "X_de_valid = [encode(t, tokenizer_de, max_len_de) for t in de_sents_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1be050b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:07:46.710655Z",
     "iopub.status.busy": "2023-03-26T15:07:46.709777Z",
     "iopub.status.idle": "2023-03-26T15:08:08.168199Z",
     "shell.execute_reply": "2023-03-26T15:08:08.167118Z"
    },
    "id": "2f0fcb7a",
    "papermill": {
     "duration": 21.473034,
     "end_time": "2023-03-26T15:08:08.170974",
     "exception": false,
     "start_time": "2023-03-26T15:07:46.697940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set = Dataset(X_en_train, X_de_train)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, batch_size=200, shuffle=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d8a5bb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:08:08.191355Z",
     "iopub.status.busy": "2023-03-26T15:08:08.191015Z",
     "iopub.status.idle": "2023-03-26T15:08:08.231650Z",
     "shell.execute_reply": "2023-03-26T15:08:08.230573Z"
    },
    "id": "6d0980a4",
    "papermill": {
     "duration": 0.053406,
     "end_time": "2023-03-26T15:08:08.233923",
     "exception": false,
     "start_time": "2023-03-26T15:08:08.180517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_set = Dataset(X_en_valid, X_de_valid)\n",
    "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463d6492",
   "metadata": {
    "id": "32bb0e70",
    "papermill": {
     "duration": 0.008921,
     "end_time": "2023-03-26T15:08:08.252085",
     "exception": false,
     "start_time": "2023-03-26T15:08:08.243164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Код трансформера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779cf012",
   "metadata": {
    "id": "54a83a16",
    "papermill": {
     "duration": 0.008775,
     "end_time": "2023-03-26T15:08:08.269840",
     "exception": false,
     "start_time": "2023-03-26T15:08:08.261065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Дальше код модели, он взят вот отсюда (с небольшими изменениями) - https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "\n",
    "Там есть комментарии по каждому этапу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "145b0475",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:08:08.290050Z",
     "iopub.status.busy": "2023-03-26T15:08:08.289700Z",
     "iopub.status.idle": "2023-03-26T15:08:08.418993Z",
     "shell.execute_reply": "2023-03-26T15:08:08.417997Z"
    },
    "id": "078605bf",
    "papermill": {
     "duration": 0.142161,
     "end_time": "2023-03-26T15:08:08.421266",
     "exception": false,
     "start_time": "2023-03-26T15:08:08.279105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 150):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size, \n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "#         print('pos inp')\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "#         print('pos dec')\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "#         print('pos out')\n",
    "        x = self.generator(outs)\n",
    "#         print('gen')\n",
    "        return x\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)\n",
    "# During training, we need a subsequent word mask that will prevent model to look into the future words when making predictions. We will also need masks to hide source and target padding tokens. Below, let’s define a function that will take care of both.\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    \n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "277a9421",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:08:08.441242Z",
     "iopub.status.busy": "2023-03-26T15:08:08.440920Z",
     "iopub.status.idle": "2023-03-26T15:08:08.453772Z",
     "shell.execute_reply": "2023-03-26T15:08:08.452893Z"
    },
    "id": "dedf9014",
    "papermill": {
     "duration": 0.02546,
     "end_time": "2023-03-26T15:08:08.455941",
     "exception": false,
     "start_time": "2023-03-26T15:08:08.430481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "def train(model, iterator, optimizer, criterion, print_every=500):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    ac = []\n",
    "    \n",
    "    model.train()  \n",
    "\n",
    "    for i, (texts_en, texts_de) in enumerate(iterator):\n",
    "        texts_en = texts_en.T.to(DEVICE) # чтобы батч был в конце\n",
    "        texts_de = texts_de.T.to(DEVICE) # чтобы батч был в конце\n",
    "        \n",
    "        # помимо текста в модель еще нужно передать целевую последовательность\n",
    "        # но не полную а без 1 последнего элемента\n",
    "        # а на выходе ожидаем, что модель сгенерирует этот недостающий элемент\n",
    "        texts_de_input = texts_de[:-1, :]\n",
    "        \n",
    "        \n",
    "        # в трансформерах нет циклов как в лстм \n",
    "        # каждый элемент связан с каждым через аттеншен\n",
    "        # чтобы имитировать последовательную обработку\n",
    "        # и чтобы не считать аттеншн с паддингом \n",
    "        # в трансформерах нужно считать много масок\n",
    "        (texts_en_mask, texts_de_mask, \n",
    "        texts_en_padding_mask, texts_de_padding_mask) = create_mask(texts_en, texts_de_input)\n",
    "        logits = model(texts_en, texts_de_input, texts_en_mask, texts_de_mask,\n",
    "                       texts_en_padding_mask, texts_de_padding_mask, texts_en_padding_mask)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # сравниваем выход из модели с целевой последовательностью уже с этим последним элементом\n",
    "        texts_de_out = texts_de[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), texts_de_out.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "        \n",
    "        if not (i+1) % print_every:\n",
    "            print(f'Loss: {np.mean(epoch_loss)};')\n",
    "        \n",
    "    return np.mean(epoch_loss)\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    epoch_f1 = []\n",
    "    \n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        for i, (texts_en, texts_de) in enumerate(iterator):\n",
    "            texts_en = texts_en.T.to(DEVICE)\n",
    "            texts_de = texts_de.T.to(DEVICE)\n",
    "\n",
    "            texts_de_input = texts_de[:-1, :]\n",
    "\n",
    "            (texts_en_mask, texts_de_mask, \n",
    "            texts_en_padding_mask, texts_de_padding_mask) = create_mask(texts_en, texts_de_input)\n",
    "\n",
    "            logits = model(texts_en, texts_de_input, texts_en_mask, texts_de_mask,\n",
    "                           texts_en_padding_mask, texts_de_padding_mask, texts_en_padding_mask)\n",
    "\n",
    "            \n",
    "            texts_de_out = texts_de[1:, :]\n",
    "            loss = loss_fn(logits.reshape(-1, logits.shape[-1]), texts_de_out.reshape(-1))\n",
    "            epoch_loss.append(loss.item())\n",
    "            \n",
    "    return np.mean(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d14bcdf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:08:08.476567Z",
     "iopub.status.busy": "2023-03-26T15:08:08.475641Z",
     "iopub.status.idle": "2023-03-26T15:08:11.627639Z",
     "shell.execute_reply": "2023-03-26T15:08:11.626514Z"
    },
    "id": "c4ea391c",
    "papermill": {
     "duration": 3.165491,
     "end_time": "2023-03-26T15:08:11.630588",
     "exception": false,
     "start_time": "2023-03-26T15:08:08.465097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "EN_VOCAB_SIZE = tokenizer_en.get_vocab_size()\n",
    "DE_VOCAB_SIZE = tokenizer_de.get_vocab_size()\n",
    "\n",
    "EMB_SIZE = 256\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "NUM_ENCODER_LAYERS = 2\n",
    "NUM_DECODER_LAYERS = 2\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, EN_VOCAB_SIZE, DE_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ab2de0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:08:11.650274Z",
     "iopub.status.busy": "2023-03-26T15:08:11.649932Z",
     "iopub.status.idle": "2023-03-26T15:08:11.654218Z",
     "shell.execute_reply": "2023-03-26T15:08:11.653106Z"
    },
    "id": "07f5b3a7",
    "papermill": {
     "duration": 0.016918,
     "end_time": "2023-03-26T15:08:11.656838",
     "exception": false,
     "start_time": "2023-03-26T15:08:11.639920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(transformer, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "541a8695",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:08:11.676239Z",
     "iopub.status.busy": "2023-03-26T15:08:11.675670Z",
     "iopub.status.idle": "2023-03-26T15:08:11.680347Z",
     "shell.execute_reply": "2023-03-26T15:08:11.679433Z"
    },
    "id": "d39a4011",
    "papermill": {
     "duration": 0.016715,
     "end_time": "2023-03-26T15:08:11.682423",
     "exception": false,
     "start_time": "2023-03-26T15:08:11.665708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transformer = torch.load('model').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67342c23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:08:11.702086Z",
     "iopub.status.busy": "2023-03-26T15:08:11.701281Z",
     "iopub.status.idle": "2023-03-26T15:08:11.706147Z",
     "shell.execute_reply": "2023-03-26T15:08:11.705256Z"
    },
    "id": "5559362d",
    "papermill": {
     "duration": 0.016736,
     "end_time": "2023-03-26T15:08:11.708068",
     "exception": false,
     "start_time": "2023-03-26T15:08:11.691332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50c9325",
   "metadata": {
    "papermill": {
     "duration": 0.008633,
     "end_time": "2023-03-26T15:08:11.725734",
     "exception": false,
     "start_time": "2023-03-26T15:08:11.717101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "(эпох мало, т.к. долго учится)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9905196b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T15:08:11.744989Z",
     "iopub.status.busy": "2023-03-26T15:08:11.744197Z",
     "iopub.status.idle": "2023-03-26T20:13:00.419317Z",
     "shell.execute_reply": "2023-03-26T20:13:00.417667Z"
    },
    "id": "2070ab9c",
    "outputId": "c0321875-233a-49fc-ee58-a482e2b26c2a",
    "papermill": {
     "duration": 18288.687108,
     "end_time": "2023-03-26T20:13:00.421665",
     "exception": false,
     "start_time": "2023-03-26T15:08:11.734557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 7.637119799613953;\n",
      "Loss: 7.011490802288056;\n",
      "Loss: 6.66494140847524;\n",
      "Loss: 6.427875431776047;\n",
      "Loss: 6.247375998878479;\n",
      "Loss: 6.100318091392517;\n",
      "Loss: 5.974966465132577;\n",
      "Loss: 5.867505427956581;\n",
      "Loss: 5.771845067871942;\n",
      "Loss: 5.684390247726441;\n",
      "First epoch - 4.769833135604858\n",
      "Epoch: 1, Train loss: 5.684, Val loss: 4.770,            Epoch time=1207.074s\n",
      "Loss: 4.772817912101746;\n",
      "Loss: 4.727994191646576;\n",
      "Loss: 4.688127451578776;\n",
      "Loss: 4.650930532693863;\n",
      "Loss: 4.612350955200196;\n",
      "Loss: 4.575618277549744;\n",
      "Loss: 4.540472996575492;\n",
      "Loss: 4.505721473693848;\n",
      "Loss: 4.470529109319051;\n",
      "Loss: 4.4378191261768345;\n",
      "Improved from 4.769833135604858 to 4.0034057855606076\n",
      "Epoch: 2, Train loss: 4.438, Val loss: 4.003,            Epoch time=1218.737s\n",
      "Loss: 4.042820899009705;\n",
      "Loss: 4.013517164945602;\n",
      "Loss: 3.993954383214315;\n",
      "Loss: 3.9717069146633146;\n",
      "Loss: 3.9504026856422425;\n",
      "Loss: 3.929262145201365;\n",
      "Loss: 3.907880992957524;\n",
      "Loss: 3.8874631922245024;\n",
      "Loss: 3.8682304849624636;\n",
      "Loss: 3.8488128133773802;\n",
      "Improved from 4.0034057855606076 to 3.5407111644744873\n",
      "Epoch: 3, Train loss: 3.849, Val loss: 3.541,            Epoch time=1219.658s\n",
      "Loss: 3.573739745616913;\n",
      "Loss: 3.562515900850296;\n",
      "Loss: 3.5513615525563558;\n",
      "Loss: 3.5389278560876845;\n",
      "Loss: 3.5285722085952758;\n",
      "Loss: 3.5185695814291638;\n",
      "Loss: 3.507869158404214;\n",
      "Loss: 3.496625251829624;\n",
      "Loss: 3.4859066503842673;\n",
      "Loss: 3.47517499127388;\n",
      "Improved from 3.5407111644744873 to 3.2855945110321043\n",
      "Epoch: 4, Train loss: 3.475, Val loss: 3.286,            Epoch time=1219.599s\n",
      "Loss: 3.2855381689071654;\n",
      "Loss: 3.2857286157608034;\n",
      "Loss: 3.2813698096275328;\n",
      "Loss: 3.2757360842227934;\n",
      "Loss: 3.2715838515281677;\n",
      "Loss: 3.2669664001464844;\n",
      "Loss: 3.2602314669064114;\n",
      "Loss: 3.2545537752509115;\n",
      "Loss: 3.2479830056296453;\n",
      "Loss: 3.243108263492584;\n",
      "Improved from 3.2855945110321043 to 3.127675485610962\n",
      "Epoch: 5, Train loss: 3.243, Val loss: 3.128,            Epoch time=1219.892s\n",
      "Loss: 3.1074205865859987;\n",
      "Loss: 3.109963108778;\n",
      "Loss: 3.1066395923296612;\n",
      "Loss: 3.10638233089447;\n",
      "Loss: 3.1030465008735657;\n",
      "Loss: 3.1002570219834644;\n",
      "Loss: 3.0976148811067854;\n",
      "Loss: 3.0950165630578996;\n",
      "Loss: 3.092213231192695;\n",
      "Loss: 3.0897497029304506;\n",
      "Improved from 3.127675485610962 to 3.022953009605408\n",
      "Epoch: 6, Train loss: 3.090, Val loss: 3.023,            Epoch time=1219.885s\n",
      "Loss: 2.9775636825561524;\n",
      "Loss: 2.9810177783966063;\n",
      "Loss: 2.98359396759669;\n",
      "Loss: 2.98680397772789;\n",
      "Loss: 2.985804935836792;\n",
      "Loss: 2.984613300005595;\n",
      "Loss: 2.983919377599444;\n",
      "Loss: 2.983109100818634;\n",
      "Loss: 2.9819808735847473;\n",
      "Loss: 2.9809704051971435;\n",
      "Improved from 3.022953009605408 to 2.94010534286499\n",
      "Epoch: 7, Train loss: 2.981, Val loss: 2.940,            Epoch time=1219.528s\n",
      "Loss: 2.8838143157958984;\n",
      "Loss: 2.892239127635956;\n",
      "Loss: 2.894801222960154;\n",
      "Loss: 2.8962779750823975;\n",
      "Loss: 2.8972699151039123;\n",
      "Loss: 2.8982279052734374;\n",
      "Loss: 2.8977561958857945;\n",
      "Loss: 2.898820086121559;\n",
      "Loss: 2.8992733132574293;\n",
      "Loss: 2.8985700379371644;\n",
      "Improved from 2.94010534286499 to 2.889992594718933\n",
      "Epoch: 8, Train loss: 2.899, Val loss: 2.890,            Epoch time=1218.899s\n",
      "Loss: 2.809323188304901;\n",
      "Loss: 2.813652535200119;\n",
      "Loss: 2.818288552284241;\n",
      "Loss: 2.8239545271396636;\n",
      "Loss: 2.8259052802085876;\n",
      "Loss: 2.8288899381955463;\n",
      "Loss: 2.8304130614825658;\n",
      "Loss: 2.83082679361105;\n",
      "Loss: 2.8312317468855115;\n",
      "Loss: 2.8327195095062256;\n",
      "Improved from 2.889992594718933 to 2.8433663129806517\n",
      "Epoch: 9, Train loss: 2.833, Val loss: 2.843,            Epoch time=1219.493s\n",
      "Loss: 2.748039067745209;\n",
      "Loss: 2.757254865169525;\n",
      "Loss: 2.7642802635828656;\n",
      "Loss: 2.7661801475286483;\n",
      "Loss: 2.769187141227722;\n",
      "Loss: 2.771791855494181;\n",
      "Loss: 2.7739788492747715;\n",
      "Loss: 2.7760201573967933;\n",
      "Loss: 2.7776498307122126;\n",
      "Loss: 2.7791864059925078;\n",
      "Improved from 2.8433663129806517 to 2.8125736713409424\n",
      "Epoch: 10, Train loss: 2.779, Val loss: 2.813,            Epoch time=1218.980s\n",
      "Loss: 2.7131392135620116;\n",
      "Loss: 2.7141395363807677;\n",
      "Loss: 2.7179446717898053;\n",
      "Loss: 2.7203300009965896;\n",
      "Loss: 2.725127487373352;\n",
      "Loss: 2.7267033664385476;\n",
      "Loss: 2.7288199116161893;\n",
      "Loss: 2.730837431550026;\n",
      "Loss: 2.732919930140177;\n",
      "Loss: 2.735088900756836;\n",
      "Improved from 2.8125736713409424 to 2.782857322692871\n",
      "Epoch: 11, Train loss: 2.735, Val loss: 2.783,            Epoch time=1218.812s\n",
      "Loss: 2.6686216921806336;\n",
      "Loss: 2.67000258398056;\n",
      "Loss: 2.6779969104131065;\n",
      "Loss: 2.6819937815666197;\n",
      "Loss: 2.6839848324775697;\n",
      "Loss: 2.686958207289378;\n",
      "Loss: 2.6899565089770725;\n",
      "Loss: 2.692835135221481;\n",
      "Loss: 2.694792147212558;\n",
      "Loss: 2.696775222301483;\n",
      "Improved from 2.782857322692871 to 2.76132755279541\n",
      "Epoch: 12, Train loss: 2.697, Val loss: 2.761,            Epoch time=1218.674s\n",
      "Loss: 2.633380742549896;\n",
      "Loss: 2.6340982677936555;\n",
      "Loss: 2.6409726999600727;\n",
      "Loss: 2.643730693221092;\n",
      "Loss: 2.648122879219055;\n",
      "Loss: 2.651082367897034;\n",
      "Loss: 2.654421083995274;\n",
      "Loss: 2.65878589373827;\n",
      "Loss: 2.6616110410690306;\n",
      "Loss: 2.6648785888671873;\n",
      "Improved from 2.76132755279541 to 2.7487728118896486\n",
      "Epoch: 13, Train loss: 2.665, Val loss: 2.749,            Epoch time=1217.764s\n",
      "Loss: 2.600868441104889;\n",
      "Loss: 2.6057944772243498;\n",
      "Loss: 2.60850266011556;\n",
      "Loss: 2.6145989142656325;\n",
      "Loss: 2.6197505436897277;\n",
      "Loss: 2.6244541472593945;\n",
      "Loss: 2.6270182170186724;\n",
      "Loss: 2.6307045190930367;\n",
      "Loss: 2.6333147689501444;\n",
      "Loss: 2.63573147354126;\n",
      "Improved from 2.7487728118896486 to 2.7377474308013916\n",
      "Epoch: 14, Train loss: 2.636, Val loss: 2.738,            Epoch time=1218.677s\n",
      "Loss: 2.5730925755500795;\n",
      "Loss: 2.578094053030014;\n",
      "Loss: 2.586701562722524;\n",
      "Loss: 2.5927282584905624;\n",
      "Loss: 2.5962200811386107;\n",
      "Loss: 2.60105900200208;\n",
      "Loss: 2.6038769448144095;\n",
      "Loss: 2.605858023405075;\n",
      "Loss: 2.608089674366845;\n",
      "Loss: 2.6105046246528625;\n",
      "Improved from 2.7377474308013916 to 2.724070835113525\n",
      "Epoch: 15, Train loss: 2.611, Val loss: 2.724,            Epoch time=1218.978s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train(transformer, training_generator, optimizer, loss_fn)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer, valid_generator, loss_fn)\n",
    "    \n",
    "    if not losses:\n",
    "        print(f'First epoch - {val_loss}')\n",
    "        #torch.save(transformer, 'model')\n",
    "    \n",
    "    elif val_loss < min(losses):\n",
    "        print(f'Improved from {min(losses)} to {val_loss}')\n",
    "        #torch.save(transformer, 'model')\n",
    "    \n",
    "    losses.append(val_loss)\n",
    "        \n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \\\n",
    "           \"f\"Epoch time={(end_time-start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f1149c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T20:13:00.460787Z",
     "iopub.status.busy": "2023-03-26T20:13:00.459758Z",
     "iopub.status.idle": "2023-03-26T20:13:00.646615Z",
     "shell.execute_reply": "2023-03-26T20:13:00.645527Z"
    },
    "papermill": {
     "duration": 0.209486,
     "end_time": "2023-03-26T20:13:00.649606",
     "exception": false,
     "start_time": "2023-03-26T20:13:00.440120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(transformer, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2929a16b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T20:13:00.686565Z",
     "iopub.status.busy": "2023-03-26T20:13:00.685706Z",
     "iopub.status.idle": "2023-03-26T20:13:00.695972Z",
     "shell.execute_reply": "2023-03-26T20:13:00.695065Z"
    },
    "id": "b234717b",
    "papermill": {
     "duration": 0.030545,
     "end_time": "2023-03-26T20:13:00.698096",
     "exception": false,
     "start_time": "2023-03-26T20:13:00.667551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "\n",
    "\n",
    "    input_ids = [tokenizer_en.token_to_id('[CLS]')] + tokenizer_en.encode(text).ids[:max_len_en] + [tokenizer_en.token_to_id('[SEP]')]\n",
    "    output_ids = [tokenizer_de.token_to_id('[CLS]')]\n",
    "\n",
    "    input_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(input_ids)]).to(DEVICE)\n",
    "    output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(output_ids)]).to(DEVICE)\n",
    "\n",
    "    (texts_en_mask, texts_de_mask, \n",
    "    texts_en_padding_mask, texts_de_padding_mask) = create_mask(input_ids_pad, output_ids_pad)\n",
    "\n",
    "    logits = transformer(input_ids_pad, output_ids_pad, texts_en_mask, texts_de_mask,\n",
    "                   texts_en_padding_mask, texts_de_padding_mask, texts_en_padding_mask)\n",
    "    pred = logits.argmax(2).item()\n",
    "\n",
    "    while pred not in [tokenizer_de.token_to_id('[SEP]'), tokenizer_de.token_to_id('[PAD]')]:\n",
    "        output_ids.append(pred)\n",
    "        output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(output_ids)]).to(DEVICE)\n",
    "\n",
    "        (texts_en_mask, texts_de_mask, \n",
    "        texts_en_padding_mask, texts_de_padding_mask) = create_mask(input_ids_pad, output_ids_pad)\n",
    "        logits = transformer(input_ids_pad, output_ids_pad, texts_en_mask, texts_de_mask,\n",
    "                       texts_en_padding_mask, texts_de_padding_mask, texts_en_padding_mask)\n",
    "        pred = logits.argmax(2)[-1].item()\n",
    "\n",
    "    return (' '.join([tokenizer_de.id_to_token(i).replace('##', '') for i in output_ids[1:]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e755af1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T20:13:00.733995Z",
     "iopub.status.busy": "2023-03-26T20:13:00.733695Z",
     "iopub.status.idle": "2023-03-26T20:13:00.775307Z",
     "shell.execute_reply": "2023-03-26T20:13:00.774045Z"
    },
    "papermill": {
     "duration": 0.062536,
     "end_time": "2023-03-26T20:13:00.777732",
     "exception": false,
     "start_time": "2023-03-26T20:13:00.715196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Antwort eine Frage'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('Answer a question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d7aff0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T20:13:00.814830Z",
     "iopub.status.busy": "2023-03-26T20:13:00.814545Z",
     "iopub.status.idle": "2023-03-26T20:13:01.362750Z",
     "shell.execute_reply": "2023-03-26T20:13:01.361733Z"
    },
    "papermill": {
     "duration": 0.569318,
     "end_time": "2023-03-26T20:13:01.365473",
     "exception": false,
     "start_time": "2023-03-26T20:13:00.796155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "715eb04b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T20:13:01.403846Z",
     "iopub.status.busy": "2023-03-26T20:13:01.402794Z",
     "iopub.status.idle": "2023-03-26T20:13:01.437519Z",
     "shell.execute_reply": "2023-03-26T20:13:01.436572Z"
    },
    "papermill": {
     "duration": 0.055851,
     "end_time": "2023-03-26T20:13:01.439732",
     "exception": false,
     "start_time": "2023-03-26T20:13:01.383881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_sents_test = open('/kaggle/input/opus-tr/opus.de-en-test.en').read().lower().splitlines()\n",
    "de_sents_test = open('/kaggle/input/opus-tr/opus.de-en-test.de').read().lower().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c589e537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T20:13:01.478434Z",
     "iopub.status.busy": "2023-03-26T20:13:01.478126Z",
     "iopub.status.idle": "2023-03-26T20:16:08.819774Z",
     "shell.execute_reply": "2023-03-26T20:16:08.818584Z"
    },
    "papermill": {
     "duration": 187.36417,
     "end_time": "2023-03-26T20:16:08.822626",
     "exception": false,
     "start_time": "2023-03-26T20:13:01.458456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "translations = []\n",
    "\n",
    "for i in range(len(en_sents_test)):\n",
    "      translations.append(translate(en_sents_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "deaef4a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T20:16:08.859571Z",
     "iopub.status.busy": "2023-03-26T20:16:08.859254Z",
     "iopub.status.idle": "2023-03-26T20:16:08.866649Z",
     "shell.execute_reply": "2023-03-26T20:16:08.865655Z"
    },
    "papermill": {
     "duration": 0.027771,
     "end_time": "2023-03-26T20:16:08.868682",
     "exception": false,
     "start_time": "2023-03-26T20:16:08.840911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['04 : 26 : 35',\n",
       " 'Vor historischen Arch ä ologie im dr itten reichen reich \".',\n",
       " \"indem Sie auf ' sa ve profile ', Sie stimmen die Benutzer stimmen , die diese Begriffe und Bedingungen zu .\",\n",
       " 'Ich wollte dir etwas zeigen .']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "805fdebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T20:16:08.906632Z",
     "iopub.status.busy": "2023-03-26T20:16:08.904932Z",
     "iopub.status.idle": "2023-03-26T20:16:08.912077Z",
     "shell.execute_reply": "2023-03-26T20:16:08.911111Z"
    },
    "papermill": {
     "duration": 0.027645,
     "end_time": "2023-03-26T20:16:08.914164",
     "exception": false,
     "start_time": "2023-03-26T20:16:08.886519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['04:26:35',\n",
       " 'prähistorische archäologie im dritten reich\".',\n",
       " 'die nutzungsbedingungen werden durch das klicken des nutzers auf \"profil speichern\" vereinbart.',\n",
       " 'ich wollte dir erst noch etwas zeigen.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_sents_test[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b753d8a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T20:16:08.950238Z",
     "iopub.status.busy": "2023-03-26T20:16:08.949941Z",
     "iopub.status.idle": "2023-03-26T20:16:09.106364Z",
     "shell.execute_reply": "2023-03-26T20:16:09.104906Z"
    },
    "papermill": {
     "duration": 0.177626,
     "end_time": "2023-03-26T20:16:09.109122",
     "exception": false,
     "start_time": "2023-03-26T20:16:08.931496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "bleus = []\n",
    "\n",
    "for i, t in enumerate(translations):\n",
    "    reference = tokenizer_de.encode(de_sents_test[i]).tokens\n",
    "    hypothesis = tokenizer_de.encode(t).tokens\n",
    "\n",
    "bleus.append(nltk.translate.bleu_score.sentence_bleu([reference], hypothesis,  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2a44ff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T20:16:09.146273Z",
     "iopub.status.busy": "2023-03-26T20:16:09.145999Z",
     "iopub.status.idle": "2023-03-26T20:16:09.152443Z",
     "shell.execute_reply": "2023-03-26T20:16:09.151396Z"
    },
    "papermill": {
     "duration": 0.02715,
     "end_time": "2023-03-26T20:16:09.154527",
     "exception": false,
     "start_time": "2023-03-26T20:16:09.127377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.250253290431036"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(bleus)/len(bleus))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b30c1c",
   "metadata": {
    "papermill": {
     "duration": 0.018172,
     "end_time": "2023-03-26T20:16:09.190065",
     "exception": false,
     "start_time": "2023-03-26T20:16:09.171893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Задание 2 (2 балла).\n",
    "Прочитайте главу про машинный перевод у Журафски и Маннига - https://web.stanford.edu/~jurafsky/slp3/10.pdf \n",
    "Ответьте своими словами в чем заключается техника back translation? Для чего она применяется и что позволяет получить? Опишите по шагам как его применить к паре en-ru на данных из семинара. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eac4c91",
   "metadata": {
    "papermill": {
     "duration": 0.018444,
     "end_time": "2023-03-26T20:16:09.226476",
     "exception": false,
     "start_time": "2023-03-26T20:16:09.208032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Когда работаем с малоресурсным языком, можно сгенерировать синтетические данные. Для этого применяется backtranslation. \n",
    "\n",
    "Мы хотим обучить переводчик en-ru. Допустим, есть какое-то количество параллельных данных (предложений, которые есть на двух языках). Это странно, но у нас есть много данных на русском (допустим).\n",
    "\n",
    "* Обучаем модель в обратную сторону, с ru-en (на малых данных). Получили переводчик. \n",
    "\n",
    "* Затем возьмем много данных на русском. Переведем их на английский язык. \n",
    "\n",
    "* Так у нас теперь есть дополнительный синтетический параллельный корпус; смешиваем с оригинальным корпусом и обучаем новую модель. \n",
    "\n",
    "! у backtranslation есть параметры. \n",
    "\n",
    "Как генерировать back translated data: декодер в greedy inference / beam search / сэмплирование.\n",
    "\n",
    "Соотношение back translated данных к нормальным данным: можно увеличить выборку \"нормальных\" данных (добавлять несколько копий каждого предложения). \n",
    "\n",
    "Вывод: обратный перевод позволяет увеличить количество данных для обучения и помогает обучить модель лучше, чем если бы мы использовали только малое количество доступных данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18768.634479,
   "end_time": "2023-03-26T20:16:12.100758",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-26T15:03:23.466279",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
